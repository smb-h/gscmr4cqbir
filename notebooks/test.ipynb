{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "from barbar import Bar\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOMSTATE = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if any accelerator is presented, if yes switch device to use CUDA or else use CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing intermediate DataFrame\n",
    "base_path = \"../data/raw/cbir/\"\n",
    "base_abs_path = os.path.abspath(base_path)\n",
    "print(base_abs_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = base_abs_path + \"/images/\"\n",
    "df = pd.DataFrame()\n",
    "dataset_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"image\"] = [f for f in os.listdir(dataset_path)]\n",
    "df[\"image\"] = df[\"image\"].apply(lambda x: dataset_path + x)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBIRDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.transformations = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        row = self.df.iloc[key]\n",
    "        image = self.transformations(Image.open(row[\"image\"]))\n",
    "        return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intermediate Function to process data from the data retrieval class\n",
    "def prepare_data(df):\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.15, random_state=RANDOMSTATE)\n",
    "    train_set = CBIRDataset(train_df)\n",
    "    valid_set = CBIRDataset(valid_df)\n",
    "    return train_set, valid_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "            # in (N, 3, 512, 512)\n",
    "        self.encoder = nn.Sequential(\n",
    "            # (32, 16, 171, 171)\n",
    "            nn.Conv2d(in_channels=3, \n",
    "                      out_channels=16, \n",
    "                      kernel_size=(3,3), \n",
    "                      stride=3, \n",
    "                      padding=1), \n",
    "            nn.ReLU(True),\n",
    "            # (N, 16, 85, 85)\n",
    "            nn.MaxPool2d(2, stride=2),  \n",
    "            # (N, 8, 43, 43)\n",
    "            nn.Conv2d(in_channels=16, \n",
    "                      out_channels=8, \n",
    "                      kernel_size=(3,3), \n",
    "                      stride=2, \n",
    "                      padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            # (N, 8, 42, 42)\n",
    "            nn.MaxPool2d(2, stride=1) \n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            # (N, 16, 85, 85)\n",
    "            nn.ConvTranspose2d(in_channels = 8, \n",
    "                               out_channels=16, \n",
    "                               kernel_size=(3,3), \n",
    "                               stride=2),  \n",
    "            nn.ReLU(True),\n",
    "            # (N, 8, 255, 255)\n",
    "            nn.ConvTranspose2d(in_channels=16, \n",
    "                               out_channels=8, \n",
    "                               kernel_size=(5,5), \n",
    "                               stride=3, \n",
    "                               padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            # (N, 3, 512, 512)\n",
    "            nn.ConvTranspose2d(in_channels=8, \n",
    "                               out_channels=3, \n",
    "                               kernel_size=(6,6), \n",
    "                               stride=2, \n",
    "                               padding=1),  \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ConvAutoencoder().to(device), (3, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder_v2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder_v2, self).__init__()\n",
    "        # in (N, 3, 512, 512)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, \n",
    "                      out_channels=64, \n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=1, \n",
    "                      padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=64, \n",
    "                      out_channels=64, \n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=1, \n",
    "                      padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2), \n",
    "            \n",
    "            nn.Conv2d(in_channels=64, \n",
    "                      out_channels=128, \n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=2, \n",
    "                      padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=128, \n",
    "                      out_channels=128, \n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=1, \n",
    "                      padding=0), \n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2), \n",
    "            \n",
    "            nn.Conv2d(in_channels=128, \n",
    "                      out_channels=256, \n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=2, \n",
    "                      padding=1), \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=256, \n",
    "                      out_channels=256, \n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=1, \n",
    "                      padding=1), \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=256, \n",
    "                      out_channels=256, \n",
    "                      kernel_size=(3, 3), \n",
    "                      stride=1, \n",
    "                      padding=1), \n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2) \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels = 256, \n",
    "                               out_channels=256, \n",
    "                               kernel_size=(3, 3), \n",
    "                               stride=1,\n",
    "                              padding=1), \n",
    " \n",
    "            nn.ConvTranspose2d(in_channels=256, \n",
    "                               out_channels=256, \n",
    "                               kernel_size=(3, 3), \n",
    "                               stride=1, \n",
    "                               padding=1),  \n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(in_channels=256, \n",
    "                               out_channels=128, \n",
    "                               kernel_size=(3, 3), \n",
    "                               stride=2, \n",
    "                               padding=0),  \n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=128, \n",
    "                               out_channels=64, \n",
    "                               kernel_size=(3, 3), \n",
    "                               stride=2, \n",
    "                               padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(in_channels=64, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=(3, 3), \n",
    "                               stride=2, \n",
    "                               padding=1), \n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=32, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=(3, 3), \n",
    "                               stride=2, \n",
    "                               padding=1),  \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=32, \n",
    "                               out_channels=3, \n",
    "                               kernel_size=(4, 4), \n",
    "                               stride=2, \n",
    "                               padding=2),  \n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ConvAutoencoder_v2().to(device),(3, 512, 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt(checkpoint_path, model, optimizer):\n",
    "    \n",
    "    # load check point\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "    # initialize state_dict from checkpoint to model\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # initialize optimizer from checkpoint to optimizer\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    # initialize valid_loss_min from checkpoint to valid_loss_min\n",
    "    # valid_loss_min = checkpoint['valid_loss_min']\n",
    "\n",
    "    # return model, optimizer, epoch value, min validation loss \n",
    "    return model, optimizer, checkpoint['epoch']\n",
    "\n",
    "def save_checkpoint(state, filename):\n",
    "    \"\"\"Save checkpoint if a new best is achieved\"\"\"\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    # save checkpoint\n",
    "    torch.save(state, filename)  \n",
    "    \n",
    "def train_model(model,  \n",
    "                criterion, \n",
    "                optimizer, \n",
    "                #scheduler, \n",
    "                num_epochs):\n",
    "    since = time.time()\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                # Set model to training mode\n",
    "                model.train()  \n",
    "            else:\n",
    "                # Set model to evaluate mode\n",
    "                model.eval()   \n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for idx,inputs in enumerate(Bar(dataloaders[phase])):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, inputs)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "            # if phase == 'train':\n",
    "            #    scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                save_checkpoint(state={   \n",
    "                                    'epoch': epoch,\n",
    "                                    'state_dict': model.state_dict(),\n",
    "                                    'best_loss': best_loss,\n",
    "                                    'optimizer_state_dict':optimizer.state_dict()\n",
    "                                },filename='ckpt_epoch_{}.pt'.format(epoch))\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, optimizer, epoch_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 150\n",
    "NUM_BATCHES = 32\n",
    "RETRAIN = False\n",
    "\n",
    "train_set, validation_set = prepare_data(df)\n",
    "dataloaders = {\n",
    "    'train': DataLoader(train_set, batch_size=NUM_BATCHES, shuffle=True, num_workers=1),\n",
    "    'val': DataLoader(validation_set, batch_size=NUM_BATCHES, num_workers=1)\n",
    "}\n",
    "dataset_sizes = {\n",
    "    'train': len(train_set),\n",
    "    'val': len(validation_set)\n",
    "}\n",
    "\n",
    "model = ConvAutoencoder_v2().to(device)\n",
    "\n",
    "criteria = nn.MSELoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If re-training is required:\n",
    "# Load the old model\n",
    "if RETRAIN == True:\n",
    "    # load the saved checkpoint\n",
    "    model, optimizer, start_epoch = load_ckpt('../input/cbirpretrained/conv_autoencoder.pt', model, optimizer)\n",
    "    print('Checkpoint Loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, loss = train_model(model=model, \n",
    "                    criterion=criteria, \n",
    "                    optimizer=optimizer, \n",
    "                    # scheduler=exp_lr_scheduler,\n",
    "                    num_epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "torch.save({\n",
    "            'epoch': EPOCHS,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, 'conv_autoencoderv2_200ep.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('gscmr4cqbir')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b34b9b54d67f9445fca51535a816c4057b03012273c4b3c57e2776c371907ea6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
